import json
import os
import openai
import time
import re
import requests

from src.services.token_prediction import token_predictor


def deep_clone(o):
    return json.loads(json.dumps(o))


def convert_message_to_chat_format(message):
    converted_message = {
        "role": "assistant" if message["isSentByMe"] else "user",
        "content": message["body"],
    }
    return converted_message


def get_system_message(ctx, messenger_name):
    system_message = {
        "role": "system",
        "content": f"You are Robot 1-X (R1X), a helpful assistant developed by the Planet Express team and integrated into a {messenger_name} chat. "
        f"More information about R1X is available at https://r1x.ai.",
    }

    return system_message


async def db_messages_to_messages(messages):
    parsed_messages = []

    for message in messages:
        if message["body"] is None:
            continue
        parsed_messages.append(convert_message_to_chat_format(message))

    return parsed_messages


async def get_limited_message_history(ctx, messages, prompt_template):
    soft_token_limit = 2048
    hard_token_limit = 4000

    messages_upto_max_tokens = await token_predictor.get_messages_upto_max_tokens(
        ctx, prompt_template, messages, soft_token_limit, hard_token_limit
    )

    if len(messages_upto_max_tokens) == 0:
        return []

    if messages_upto_max_tokens[0]["role"] == "assistant":
        messages_upto_max_tokens.pop(0)

    merged_messages = []
    prev_role = None

    for message in messages_upto_max_tokens:
        if message["role"] == prev_role:
            merged_messages[-1]["content"] += f"\n{message['content']}"
        else:
            merged_messages.append(message)

        prev_role = message["role"]

    return merged_messages


async def get_chat_completion(ctx, messenger_name, messages):
    parsed_messages = await db_messages_to_messages(messages)

    system_message = get_system_message(ctx, messenger_name)
    messages_upto_max_tokens = await get_limited_message_history(
        ctx, parsed_messages, system_message
    )

    return get_chat_completion_core(ctx, messenger_name, messages_upto_max_tokens)

async def get_chat_completion_core(ctx, messenger_name, messages):
    model = "gpt-4" if ctx.get("userChannel") == "canary" else "gpt-3.5-turbo"

    try:
        ctx.log("invoking completion request.")
        completion = await openai.create_chat_completion(
            model=model,
            messages=messages,
            temperature=0.2
        )

        ctx.log("getChatCompletionCore response: ", completion.data.choices[0].message.content)

        return {
            "response": completion.data.choices[0].message.content,
            "promptTokens": completion.data.usage.prompt_tokens,
            "completionTokens": completion.data.usage.completion_tokens
        }
    except Exception as e:
        if hasattr(e, "response"):
            ctx.log("error: ", e.response.status, e.response.data)
        else:
            ctx.log("error: ", e.message)

        ctx.log("error generating completion from OpenAI.")
        raise Exception("error generating completion from OpenAI.")


async def get_prep_message(ctx, messenger):
    current_date = time.strftime("%B %d, %Y", time.gmtime())

    prep_message_canary = {
        "role": "user",
        "content": f"""
You are Robot 1-X (R1X), a helpful assistant developed by the Planet Express team and integrated into a {messenger} chat. More info: https://r1x.ai.

You have access to SPECIFIC tools. Provide answers or fulfill requests based on the CHAT, provided DATA using those tools.
I will provide you with a CHAT between R1X and a human; the CHAT will be wrapped with tags, as such: <yair1xigor>CHAT</yair1xigor>. Last speaker is the user.
I will provide you with DATA generated by previous tool invocations, which you can rely on for your answers; this DATA will be wrapped with tags, as such: <r1xdata>DATA</r1xdata>.
Do not contradict or doubt the DATA, and do not mention its source.

You can use SEARCH or WEATHER tools. To invoke a tool, reply with a JSON formatted answer within <yair1xigoresponse> tags.
Example:

<yair1xigoresponse>{{"TOOL" : "SEARCH", "TOOL_INPUT" : "search prompt", "REASON" : "reason for search"}}</yair1xigoresponse>
<yair1xigoresponse>{{"TOOL" : "WEATHER", "TOOL_INPUT" : "City, Country", "REASON" : "reason for weather request"}}</yair1xigoresponse>

IMPORTANT: Use these exact formats and never deviate.
Do not invoke a tool if it's already used or if required input is missing or vague.

The SEARCH tool performs a Google search and returns key results. Use this tool to provide up-to-date information about world events. Its data is more reliable than your existing knowledge.
The WEATHER tool provides per-location weather forecast only for the next 5 days, at day granularity.

When providing your final reply, ALWAYS wrap the answer in <yair1xigoresponse> tags and use the following format:
<yair1xigoresponse>{{"ANSWER" : "Your answer"}}</yair1xigoresponse>
IMPORTANT: Use this exact format and never deviate.

Today's date is {current_date}.
Consider your knowledge until September 2021. If a request has no time context, assume current time. Do not mention tools directly to the user.

Follow these steps:
1. Identify the human's most recent message.
2. Create a self-contained question, including relevant data from chat and tool invocations.
3. State the most appropriate tool and input, listing prerequisites and how they are met.
4. Provide the tool invocation request or answer in JSON format wrapped within <yair1xigoresponse> tags: <yair1xigoresponse>RESPONSE</yair1xigoresponse>.
Example response:
</yair1xigoresponse>{ "ANSWER" : "Your answer" }</yair1xigoresponse>

Focus on the most recent request from the user, even if it's repeated. Do not invoke a tool if the required information was already provided by a previous tool invocation.""" }

    prep_message_stable = {
        "role" : "user",
        "content" : f"""
You are Robot 1-X (R1X), a helpful assistant developed by the Planet Express team and integrated into a {messenger} chat. More information about you is available at https://r1x.ai.

I will provide you with a chat between R1X and a human; the chat will be wrapped with tags, as such: <yair1xigor>CHAT</yair1xigor>. Last speaker is the user.
I will also provide you with data generated by previous tool invocations, which you can rely on for your answers; this data will be wrapped with tags, as such: <r1xdata>DATA</r1xdata>.

IMPORTANT: Before invoking a tool or providing an answer, follow these steps:
1. CHECK IF DATA FROM A TOOL IS ALREADY PROVIDED TO YOU in the <r1xdata> tag.
2. If data is provided in the <r1xdata> tag, DO NOT invoke the tool again.
3. Instead, use the provided data to create an appropriate answer to the user's request.

DO NOT CONTRADICT THAT DATA AND DO NOT DOUBT THAT DATA. THAT DATA SUPERSEDES ANY OTHER DATA YOU ARE AWARE OF.
DO NOT MENTION TO THE USER THIS DATA WAS RETURNED BY A SEARCH TOOL OR PROVIDED TO YOU IN ANY WAY.
DO NOT PROVIDE THE TOOL INVOCATION RESPONSE LINE IN YOUR REPLY.

Your task is to provide R1X's answer.

You can invoke one of the following tools to augment your knowledge before replying:

SEARCH: performs a Google search and returns key results. Use this tool to provide up-to-date information about world events. Its data is more reliable than your existing knowledge. TOOL_INPUT=search prompt. IMPORTANT: do not invoke this tool again if it was already invoked, and you have the result of the previous invocation.
WEATHER: per-location 5-day weather forecast, at day granularity. It does not provide a finer-grained forecast. TOOL_INPUT=<City, Country>, both in English. TOOL_INPUT should always be a well-defined settlement and country/state. IMPORTANT: If you believe the right value for TOOL_INPUT is unknown/my location/similar, do not ask for the tool to be invoked and instead use the ANSWER format to ask the user for location information.

For invoking a tool, provide your reply in a JSON format, with the following fields: TOOL, TOOL_INPUT, REASON.
Examples:

{ "TOOL" : "SEARCH", "TOOL_INPUT" : "Who is the current UK PM?", "REASON" : "Human requested data about UK government." }
{ "TOOL" : "WEATHER", "TOOL_INPUT" : "Tel Aviv, Israel", "REASON" : "Human is located in Tel Aviv, Israel and asked what to wear tomorrow." }

Please use these exact formats, and do not deviate.

Otherwise, provide your final reply in a JSON format, with the following fields: ANSWER.
Example:

{ "ANSWER" : "Rishi Sunak" }

Today's date is XXXXXX.
You are trained with knowledge until September 2021.
For factual information about people, stocks and world events, use one of the tools available to you before replying.
For fiction requests, use your knowledge and creativity to answer. Be verbose.
If human request has no context of time, assume he is referring to current time period.
In all cases, do not respond that your knowledge is not up to date unless a tool invocation has already happened for you in that context. Additionally, do not invoke a tool if the required TOOL_INPUT is unknown, vague, or not provided. Always follow the IMPORTANT note in the tool description.
Finally, do not invoke a tool if the required information was already provided by a previous tool invocation, whose data is provided to you.


Don't provide your response until you made sure it is valid, and meets all prerequisites laid out for tool invocation.

WHEN PROVIDING A FINAL ANSWER TO THE USER, NEVER MENTION THE SEARCH AND WEATHER TOOLS DIRECTLY, AND DO NOT SUGGEST THAT THE USER UTILIZES THEM.

Your tasks are as follows:

1. Formulate the request from the human in their last message.
2. Formulate the human's request as a self-contained question, including all relevant data from previous messages in the chat, as well as data from tool invocations.
3. State which tool should be invoked can provide the most information, and with what input. List all prerequisites for the tool and show how each is met. IMPORTANT: it is not allowed to invoke a tool that already has data provided to in in the <r1xdata> section.
4. Formulate the tool invocation request, or answer, in JSON format as detailed above. JSON should be delimited as <yair1xigoresponse>RESPONSE</yair1xigoresponse>. IMPORTANT: THE "RESPONSE" PART MUST BE DELIVERED IN A SINGLE LINE. DO NOT USE MULTILINE SYNTAX.

Use the following format when provicing your answer:

Human's most recent message: <request>
Self-contained request: <human's most recent request, including all relevant data from chat history>
Tool invocation request: <information about which tool is most relevant, if any, including explanation how each prerequisite for the tool is met with detailed data. confirm that you have verified that this tool has not been invoked yet, as it is illegal to invoke again>
Response: <yair1xigoresponse><tool request or answer in JSON format></yair1xigoresponse>

IMPORTANT: Make sure to focus on the most recent request from the user, even if it is a repeated one.""" }

    return prep_message_canary if ctx.get('channel') == 'canary' else prep_message_stable

prepReplyMessage = {"role": "assistant", "content": "Understood. Please provide me with the chat between R1X and the human."}

async def getChatCompletionWithTools(ctx, messengerName, messages, direct):
    try:
        ctx.log("Starting getChatCompletionWithTools.")

        parsedMessages = await deepClone(messages) if direct else await dbMessages2Messages(messages)
        ctx.log({"messages": parsedMessages})

        prevResponses = []

        systemMessage = getSystemMessage(ctx, messengerName)
        history = await getLimitedMessageHistory(ctx, parsedMessages, systemMessage)

        for i in range(2):
            ctx.log(f"Invoking completionIterativeStep #{i}")
            answer, tool, input = await completionIterativeStep(ctx, messengerName, deepClone(history), prevResponses)
            ctx.log(f"completionIterativeStep done, answer={answer} tool={tool} input={input}")

            if answer:
                ctx.log(f"Answer returned: {answer}")

                return {
                    "response": answer,
                    "promptTokens": 0,
                    "completionTokens": 0
                }

            if tool and input:
                ctx.log(f"Invoking TOOL {tool} with INPUT {input}")
                response = await invokeTool(ctx, tool, input)
                prevResponses.append(f"INVOKED TOOL={tool}, TOOL_INPUT={input}, ACCURACY=100%, INVOCATION DATE={datetime.datetime.now().date()} RESPONSE={response}")

    except Exception as e:
        ctx.log({"e": e})

    ctx.log("getChatCompletionWithTools: failed generating customized reply, falling back to getChatCompletion.")

    return getChatCompletion(ctx, messengerName, messages)

def escapeSpecialChars(str):
    return str.translate(str.maketrans({
        "\n": "\\n",
        "\r": "\\r",
        "\t": "\\t",
        "\b": "\\b",
        "\f": "\\f",
        "\\": "\\\\",
        "'": "\\'",
        "\"": "\\\""
    }))

def completion_iterative_step(ctx, messenger_name, history, prev_responses):
    result = {'answer': None, 'tool': None, 'input': None}

    messages = []

    new_request = {'role': 'user', 'content': ''}
    new_request['content'] += 'Here is the chat so far:\n<yair1xigor>'

    for message in history:
        speaker = 'R1X' if message['role'] == 'assistant' else 'Human'
        new_request['content'] += f'\n<{speaker}>: {message["content"]}'

    new_request['content'] += '\n<R1X:></yair1xigor>'

    if prev_responses:
        prev_responses_flag = '\n'.join(prev_responses)
        new_request['content'] += f'\nhere is the data so far:\n\n<r1xdata>{prev_responses_flat}</r1xdata>\n'

    prep_message = get_prep_message(ctx, messenger_name)
    messages.append(prep_message)
    messages.append(prep_reply_message)

    messages.append(new_request)

    ctx.log({'messages': messages})

    reply = get_chat_completion_core(ctx, messenger_name, messages)

    regex = re.compile(r'<yair1xigoresponse>(.*?)<\/yair1xigoresponse>', re.DOTALL)
    matches = regex.search(reply['response'])

    if not matches:
        return 0

    escaped_match = escape_special_chars(matches.group(1))
    ctx.log(f'completionIterativeStep: matched response: {escaped_match}')

    json_reply = json.loads(escaped_match)

    result['answer'] = json_reply['ANSWER']
    if result['answer']:
        return result

    if json_reply['TOOL'] and json_reply['TOOL_INPUT']:
        result['tool'] = json_reply['TOOL']
        result['input'] = json_reply['TOOL_INPUT']
        return result

    return result

def invoke_tool(ctx, tool, input):
    tool_canon = tool.strip().upper()

    if tool_canon.startswith('SEARCH'):
        # Replace this with an appropriate call to the Serper module
        # from langchain.tools import Serper
        ctx.log(f'Invoking Google search using SERPER, input={input}')
        # serper = Serper()
        # answer = serper.call(input)
        answer = 'SEARCH_RESULT_PLACEHOLDER'  # Placeholder
        ctx.log(f'SERPER search result: {answer}')

        return answer

    if tool_canon.startswith('WEATHER'):
        answer = invoke_weather_search(ctx, input)

        return answer

    return None

def parse_geolocation(location_data):
    regex = re.compile(r'^(\d+\.\d+)\° ([NSEW]),\s*(\d+\.\d+)\° ([NSEW])$')
    match = regex.match(location_data)

    if not match:
        return None

    lat = float(match.group(1)) * (-1 if match.group(2) == 'S' else 1)
    lon = float(match.group(3)) * (-1 if match.group(4) == 'W' else 1)

    return {'lat': lat, 'lon': lon}

def invoke_weather_search(ctx, input):
    ctx.log(f'invokeWeatherSearch, input={input}')

    # Replace this with an appropriate call to the Serper module
    # from langchain.tools import Serper
    # serper = Serper()
    # geo_res = serper.call(f'{input} long lat')
    geo_res = 'GEO_RESULT_PLACEHOLDER'  # Placeholder

    lat, lon = parse_geolocation(geo_res)

    ctx.log(f'Geolocation: lat={lat} lon={lon}')

    w_res = requests.get(f'https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&daily=temperature_2m_max,temperature_2m_min,precipitation_hours,precipitation_probability_max,windspeed_10m_max&forecast_days=3&timezone=auto')
    w_res_json = w_res.json()

    return json.dumps(w_res_json['daily'])

async def create_transcription(ctx, mp3_file_path):
    t0 = time.time()

    # Replace this with an appropriate call to the OpenAI API
    # transcription = await openai.create_transcription(  
    #     open(mp3_file_path, 'rb'),
    #     os.environ['OPENAI_SPEECH_TO_TEXT_MODEL'],
    # )
    transcription = {'data': {'text': 'TRANSCRIPTION_PLACEHOLDER'}}  # Placeholder

    time_taken = int((time.time() - t0) * 1000)

    ctx.log(f'createTranscription: timeTaken={time_taken}ms transcription={transcription["data"]["text"]}')
    return transcription['data']['text']
